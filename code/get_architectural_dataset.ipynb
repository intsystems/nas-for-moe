{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1f470d1e-7c28-40d8-b002-0dddbc1dd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.insert(0, '/pbabkin/nas-for-moe/code')\n",
    "import nas_moe.vae\n",
    "import nas_moe.dataset\n",
    "import nas_moe.surrogate\n",
    "import nas_moe.single_arch\n",
    "import nas_moe.graph\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm import tqdm\n",
    "from nni.nas.hub.pytorch import DARTS as DartsSpace\n",
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a542d130-50d6-4052-bd52-0c0bf3a1c09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='/pbabkin/nas-for-moe/code/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "split_valid = int(10000)\n",
    "num_samples = len(train_dataset)\n",
    "indices = list(range(num_samples))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "valid_subset = Subset(train_dataset, indices[split_valid:])\n",
    "valid_labels = [label for im, label in valid_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "93a6128d-9e8f-44b7-bdc8-01aca844f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "latent_space = nas_moe.vae.LatentSpace(LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d49c760-730c-43b2-918a-0645bc994f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d28926c8-0395-40a6-9cca-2984d2196c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2] Loss: 81.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latent_space.train_vae(train_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dc84dba5-8f8d-4b33-83e0-19c27696afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма данных: (40000, 64)\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img, label in valid_subset:\n",
    "    if True:\n",
    "        z = latent_space.encode_image(img)  # Получаем латентный вектор (тензор)\n",
    "        images.append(z.cpu().numpy())  # Переводим в numpy\n",
    "    else:\n",
    "        img_array = (img.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        img_flat = img_array.flatten()\n",
    "        images.append(img_flat)\n",
    "\n",
    "    labels.append(label)\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"Форма данных: {X.shape}\")\n",
    "# 3072 - просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5de350e-0774-4777-a9f6-e9ab9ba4ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных кластеров: 10\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42, n_init=10, verbose=0)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "print(f\"Количество уникальных кластеров: {len(np.unique(clusters))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "35f6e3c0-af63-4d4c-9c88-7631a7cb6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/pbabkin/nas-for-moe/code/data/CIFAR10_div/CIFAR10_div/architectures')\n",
    "model_dicts_paths = [base_path / p for p in os.listdir(base_path)]\n",
    "dataset_cluster_acc = nas_moe.dataset.ArchClusterACCDataset(\n",
    "    model_dicts_paths, \n",
    "    clusters,\n",
    "    valid_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0746ce6c-5a25-4616-bb15-ac8fa0bc3a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[21, 8], edge_index=[2, 29], y=[1, 10], index=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cluster_acc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea6e8d9c-d1b9-458a-bd9e-d138076c6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "surr = nas_moe.surrogate.GAT(8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "664aa2be-e98d-4722-a962-eb44ac55d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_graphs(batch):\n",
    "    \"\"\"\n",
    "    Объединяет список Data объектов в один Batch\n",
    "    \"\"\"\n",
    "    return Batch.from_data_list(batch)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_cluster_acc,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_graphs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9c23945d-c273-40e8-8ef1-dfb41a7b8d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [07:56<00:00,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "surr.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(surr.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    surr.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        output = surr(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "        loss = criterion(output, batch.y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ceb3c7-8846-41a6-a9c6-c1ef7eac9111",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d443e623-a584-4374-9bcc-fb68093cf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_space = DartsSpace(\n",
    "    width=16,\n",
    "    num_cells=8,\n",
    "    dataset='cifar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eee2c325-91d3-446d-b3fc-13e11d22447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_dicts = []\n",
    "archGenerator = nas_moe.single_arch.ArchitectureGenerator(model_space, 8, 3)\n",
    "K = 10000\n",
    "arch_dicts += [archGenerator.generate_arch()['architecture'] for _ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd99dd91-e71b-42de-bf41-1f8eef62153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "surr.cpu()\n",
    "\n",
    "def inference_surr(arch):\n",
    "    graph = nas_moe.graph.Graph(arch, index=0)\n",
    "    adj, _, features = graph.get_adjacency_matrix()\n",
    "    \n",
    "    features = torch.tensor(features, dtype=torch.float)\n",
    "    adj = torch.tensor(adj, dtype=torch.float)\n",
    "    \n",
    "    edge_index, _ = dense_to_sparse(adj)\n",
    "    \n",
    "    batch = torch.zeros(features.size(0), dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = surr(features, edge_index, batch)\n",
    "    return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8349dacb-a323-471d-b1b5-0ff3ce7d2c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:32<00:00, 107.84it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_accs = [inference_surr(arch) for arch in tqdm(arch_dicts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7d256ebc-7328-4de3-867c-49df4e6de6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 values: tensor([[0.8747, 0.7712, 0.8515, 0.8066, 0.7858, 0.8335, 0.8673, 0.8084, 0.7968,\n",
      "         0.8312],\n",
      "        [0.8616, 0.7651, 0.8497, 0.7981, 0.7820, 0.8244, 0.8614, 0.8020, 0.7837,\n",
      "         0.8289],\n",
      "        [0.8587, 0.7637, 0.8474, 0.7958, 0.7799, 0.8235, 0.8573, 0.8006, 0.7829,\n",
      "         0.8287]])\n",
      "Top 2 indices: tensor([[5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844],\n",
      "        [6621, 3956, 6621, 1072, 3185, 6336, 6336, 1463, 1463, 1463],\n",
      "        [1521, 1990, 6336, 1521, 1463, 4668, 3185, 4668, 6336, 1521]])\n",
      "Second max indices: tensor([1521, 1990, 6336, 1521, 1463, 4668, 3185, 4668, 6336, 1521])\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(cluster_accs)  # shape (5, 10)\n",
    "\n",
    "# get top 2 values and their indices along dim=0 (for each of the 10 columns)\n",
    "top2_values, top2_indices = torch.topk(stacked, k=3, dim=0)\n",
    "\n",
    "print(\"Top 2 values:\", top2_values)       # shape (2, 10)\n",
    "print(\"Top 2 indices:\", top2_indices)     # shape (2, 10)\n",
    "\n",
    "# Second maximum indices (index of the second highest value per column)\n",
    "second_max_indices = top2_indices[2]\n",
    "\n",
    "print(\"Second max indices:\", second_max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ea842594-e80c-4fe4-8c91-c70f776d5fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max indices: tensor([5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844])\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(cluster_accs)  # shape (5, 10)\n",
    "max_indices = torch.argmax(stacked, dim=0)  # shape (10,)\n",
    "print(\"Max indices:\", max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1491e68d-bf5e-43cb-a191-748f7fe2217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.8747, 0.7712, 0.8515, 0.8066, 0.7858, 0.8335, 0.8673, 0.8084, 0.7968,\n",
       "        0.8312]),\n",
       "indices=tensor([5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844, 5844]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(stacked, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151680b7-9854-450b-9b9d-8662719f8ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b1e1b-f2f1-4378-932e-6e0073f3c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae4627-8bc8-41ea-9fd1-7bbe37abc316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd699d-079f-4a29-a711-b718fde05989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c9f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.insert(0, '/pbabkin/nas-for-moe/code')\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff171700-9a94-41d6-9d43-73cc5bf16d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nas_moe.graph\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174ee754-7c36-42bb-9d22-3e472910adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('./data/CIFAR10_acc/trained_models_archs_1')\n",
    "json_paths = [Path(x) for x in os.listdir(folder_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1cb057-89fb-47e0-9b7f-f4d914d88497",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predictions_list = []\n",
    "valid_acc_list = []\n",
    "architecture_list = []\n",
    "\n",
    "for json_path in json_paths:\n",
    "    with open(folder_path / json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    valid_predictions_list += [data['valid_predictions']]\n",
    "    valid_acc_list += [data['valid_accuracy']]\n",
    "    architecture_list.append(data['architecture'])\n",
    "        \n",
    "    file_path = Path(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183a9759-c38c-4ff1-b09c-07b1b6aa5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nas_moe.graph.Graph(architecture_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a562c1c-0396-431d-af19-73058a00fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix, operations, one_hot_ops = graph.get_adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20a5f34-f9b9-476c-b1af-e1eaa9045ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701bc66-7203-42e0-85ae-c6ead7d37007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2365b94b-bf86-46e1-a45e-5c8d3209b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nas_moe.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe249a4-da48-466d-90ad-d3dba0483f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nas_moe.dataset.ArchClusterACCDataset"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cluster_acc = nas_moe.dataset.ArchClusterACCDataset(\n",
    "    './data/CIFAR10_acc/trained_models_archs_1', \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa757e6a-617f-4e6d-9df4-caf1d690c651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
